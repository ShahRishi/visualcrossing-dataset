{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = pd.read_csv('./data/safegraph-stores-geocode-out-manual.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Template for New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of geocodes: 1026\n"
     ]
    }
   ],
   "source": [
    "geocode_dict = {}\n",
    "geocodes = []\n",
    "\n",
    "# make dictionary of all cities\n",
    "for i in range(len(df_source)):\n",
    "    curr_geocode = str(df_source.loc[i, \"geocode\"])\n",
    "    curr_geocode = curr_geocode[1:-1]\n",
    "    geocode_dict[curr_geocode] = [df_source.loc[i, \"address\"], df_source.loc[i, \"city\"], \n",
    "                                  str(df_source.loc[i, \"zip_code\"]), str(df_source.loc[i, \"store_skey\"])]\n",
    "\n",
    "# make list of lists to pass as input to make dataframe\n",
    "for key in geocode_dict:\n",
    "    geocodes += [key]\n",
    "print('Number of geocodes:', len(geocode_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/1026 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors with 28.8919567,-82.4836527 on 2018-09-04\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-05\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-06\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-07\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-08\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-09\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-10\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-11\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-12\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-13\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-14\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-15\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-16\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-17\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-18\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-19\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-20\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-21\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-22\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-23\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-24\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-25\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-26\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-27\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-28\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-29\n",
      "Errors with 28.8919567,-82.4836527 on 2018-09-30\n",
      "Errors with 28.8919567,-82.4836527 on 2018-10-01\n",
      "Errors with 28.8919567,-82.4836527 on 2018-10-02\n"
     ]
    }
   ],
   "source": [
    "for geocode in tqdm(geocodes):\n",
    "    curr_date = datetime.date(2018, 9, 3)\n",
    "    while curr_date <= datetime.date(2022, 5, 29):\n",
    "        try:\n",
    "            start_date = curr_date\n",
    "            final_date = start_date + datetime.timedelta(days=15)\n",
    "            start_date_string = str(start_date)\n",
    "            final_date_string = str(final_date)\n",
    "            \n",
    "            json_data = requests.get(\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\" + str(geocode) + \"/\" + start_date_string + \"/\" + final_date_string + \"?unitGroup=us&key=3FWLMZ9MF7M7QBH73WCBXT2QF&contentType=json&forecastBasisDate=\" + start_date_string).json()\n",
    "            df = pd.DataFrame(json_data[\"days\"])\n",
    "            df['geocode'] = geocode\n",
    "            df.to_csv('./data/forecast_weather.csv', index=False, mode='a')\n",
    "            curr_date = final_date + datetime.timedelta(days=1)\n",
    "        except:\n",
    "            curr_date = curr_date + datetime.timedelta(days=1)\n",
    "            print('Errors with', str(geocode), 'on', str(curr_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING CELL\n",
    "city = 'boston'\n",
    "curr_date = datetime.date(2020, 1, 1)\n",
    "while curr_date <= datetime.date(2021, 12, 31):\n",
    "    start_date = curr_date\n",
    "    final_date = start_date + datetime.timedelta(days=15)\n",
    "    start_date_string = str(start_date)\n",
    "    final_date_string = str(final_date)\n",
    "\n",
    "    json_data = requests.get(\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/\" + urllib.parse.quote_plus(city[0]) + \"/\" + start_date_string + \"/\" + final_date_string + \"?unitGroup=us&key=3FWLMZ9MF7M7QBH73WCBXT2QF&contentType=json&forecastBasisDate=\" + start_date_string).json()\n",
    "    df = pd.DataFrame(json_data[\"days\"])\n",
    "    df['City'] = city[0]\n",
    "    col = df.pop('City')\n",
    "    df.insert(0, col.name, col)\n",
    "    df.to_csv('forecast_data_template.csv', index=False, mode='a', header=True)\n",
    "    curr_date = final_date + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('forecast_data.csv', error_bad_lines=False, header=None, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['City',\n",
    "              'datetime',\n",
    "              'datetimeEpoch',\n",
    "              'tempmax',\n",
    "              'tempmin',\n",
    "              'temp',\n",
    "              'feelslikemax',\n",
    "              'feelslikemin',\n",
    "              'feelslike',\n",
    "              'dew',\n",
    "              'humidity',\n",
    "              'precip',\n",
    "              'precipprob',\n",
    "              'precipcover',\n",
    "              'preciptype',\n",
    "              'snow',\n",
    "              'snowdepth',\n",
    "              'windgust',\n",
    "              'windspeed',\n",
    "              'winddir',\n",
    "              'pressure',\n",
    "              'cloudcover',\n",
    "              'visibility',\n",
    "              'solarradiation',\n",
    "              'solarenergy',\n",
    "              'uvindex',\n",
    "              'severerisk',\n",
    "              'sunrise',\n",
    "              'sunriseEpoch',\n",
    "              'sunset',\n",
    "              'sunsetEpoch',\n",
    "              'moonphase',\n",
    "              'conditions',\n",
    "              'description',\n",
    "              'icon',\n",
    "              'stations',\n",
    "              'source',\n",
    "              'hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('forecast_data_out.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
